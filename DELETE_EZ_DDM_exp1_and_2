## This script runs the EZ drift diffusion model on experiment 1 and 2

# Install necessary packages (if not already installed)
install.packages("devtools")
install.packages("ez")
library(ez)
library(tidyr)
library(dplyr)
library(rtdists)
library(brms)

# Clear the workspace
rm(list = ls())

# Set the working directory to the folder containing the participant files
setwd("/Users/slava/Library/Mobile Documents/com~apple~CloudDocs/Desktop/Analysis_online_experiments/4th_online_experiment/excl_outliers")

# Read data
data <- read.csv("regression_input.csv")

# Filter out NAs in the relevant columns
data_clean <- data %>%
  filter(!is.na(binary_question_key_resp.rt) & 
           !is.na(binary_question_key_resp.keys) & 
           !is.na(condition))

# Recode the binary responses as 0 and 1 for easier processing (as numeric values)
data_clean$binary_question_key_resp.keys <- recode(data_clean$binary_question_key_resp.keys,
                                                   "left" = 0,   # Recode "left" as 0
                                                   "right" = 1)  # Recode "right" as 1

# Make sure 'condition' is a factor
data_clean$condition <- factor(data_clean$condition, levels = c("HSDP", "LSDP", "HSDA", "LSDA"))

# Fit the drift diffusion model using 'wiener' family for the group-level analysis
model <- brm(formula = bf(binary_question_key_resp.rt | dec(binary_question_key_resp.keys) ~ condition),
             data = data_clean, 
             family = wiener(),  # Drift-diffusion model
             prior = c(
               # Prior for fixed effects (condition effects)
               set_prior("normal(0, 5)", class = "b"),  # Apply to the fixed effects
               
               # Prior for intercept (baseline reaction time)
               set_prior("normal(0, 5)", class = "Intercept")
             ),
             chains = 4,
             iter = 2000,
             warmup = 1000,
             control = list(adapt_delta = 0.95))

# View the results
summary(model)

# Note: No need to specify priors for v, a, and t0 directly. 
# The parameters for the drift diffusion model (e.g., drift rate v, threshold separation a, non-decision time t0) 
# are defined within the wiener() family and do not need to be manually specified.

# Clear the workspace
rm(list = ls())

# Set the working directory to the folder containing the participant files
setwd("/Users/slava/Library/Mobile Documents/com~apple~CloudDocs/Desktop/Analysis_online_experiments/4th_online_experiment/excl_outliers")

# Read the data from your CSV file
data <- read.csv("regression_input.csv")

# Filter out NAs in the relevant columns
data_clean <- data %>%
  filter(!is.na(binary_question_key_resp.rt) & 
           !is.na(binary_question_key_resp.keys) & 
           !is.na(condition))

# Recode the binary responses as 0 and 1 for easier processing (as numeric values)
# Recode "left" as 0 and "right" as 1 (or use 1/0 if the data is already numeric)
data_clean$binary_question_key_resp.keys <- recode(data_clean$binary_question_key_resp.keys,
                                                   "left" = 1,   # Recode "left" as 0
                                                   "right" = 0)  # Recode "right" as 1

# Make sure 'condition' is a factor
data_clean$condition <- factor(data_clean$condition, levels = c("HSDP", "LSDP", "HSDA", "LSDA"))

# Now, we need to aggregate the data by condition to calculate EZ model parameters
# This is where the analysis is done, using the DDM approximations for each condition

# Function to calculate drift rate (v), threshold separation (a), and non-decision time (t0)
# Using EZ's closed-form approximations (Wagenmakers et al., 2007)

# The formula assumes we have RTs and binary responses
calculate_ez_parameters <- function(data) {
  # Aggregating data by condition
  condition_data <- data %>%
    group_by(condition) %>%
    summarise(
      mean_rt = mean(binary_question_key_resp.rt, na.rm = TRUE),
      mean_choice = mean(binary_question_key_resp.keys, na.rm = TRUE),
      sd_rt = sd(binary_question_key_resp.rt, na.rm = TRUE)
    )
  
  # Calculate the drift rate (v), boundary separation (a), and non-decision time (t0) using the EZ formulas
  condition_data$drift_rate <- condition_data$mean_choice / condition_data$sd_rt  # Approximation for v
  condition_data$boundary_separation <- condition_data$sd_rt * 2  # Approximation for a
  condition_data$non_decision_time <- condition_data$mean_rt / 2  # Approximation for t0
  
  return(condition_data)
}

# Run the EZ model on the data and extract parameters
ez_params <- calculate_ez_parameters(data_clean)

# View the parameters
print(ez_params)
summary (ez_params)

# Load necessary libraries
library(tidyverse)

# EZ model function from Wagenmakers et al. (2007)
EZ = function(Pc, VRT, MRT, n=length(Pc), s=1.) {
  s2 = s^2
  
  # Edge correction for Pc
  if (any(Pc == 1)) {
    Pc = 1 - (1 / (2 * n))
  } else if (any(Pc == 0)) {
    Pc = (1 / (2 * n))
  } else if (any(Pc == .5)) {
    Pc = 0.5 + (1 / (2 * n))
  }
  
  # Logit transformation
  L = qlogis(Pc)
  
  # Drift rate calculation (v)
  x = L * (L * Pc^2 - L * Pc + Pc - 0.5) / VRT
  v = sign(Pc - 0.5) * s * x^(1/4)
  
  # Boundary separation calculation (a)
  a = s2 * qlogis(Pc) / v
  
  # Mean decision time (MDT) calculation
  y = -v * a / s2
  MDT = (a / (2 * v)) * (1 - exp(y)) / (1 + exp(y))
  
  # Non-decision time calculation (Ter)
  Ter = MRT - MDT
  
  return(list(v = v, a = a, Ter = Ter))
}

# EZ DDM based on Wagenmakers adapted from Copeland ----------------------------

# Clear the workspace
rm(list = ls())

# Read your data
data <- read.csv("/Users/slava/Library/Mobile Documents/com~apple~CloudDocs/Desktop/Analysis_online_experiments/4th_online_experiment/excl_outliers/regression_input.csv")

# EZ model function from Wagenmakers et al. (2007)
EZ = function(Pc, VRT, MRT, n=length(Pc), s=1.) {
  s2 = s^2
  
  # Edge correction for Pc
  if (any(Pc == 1)) {
    Pc = 1 - (1 / (2 * n))
  } else if (any(Pc == 0)) {
    Pc = (1 / (2 * n))
  } else if (any(Pc == .5)) {
    Pc = 0.5 + (1 / (2 * n))
  }
  
  # Logit transformation
  L = qlogis(Pc)
  
  # Drift rate calculation (v)
  x = L * (L * Pc^2 - L * Pc + Pc - 0.5) / VRT
  v = sign(Pc - 0.5) * s * x^(1/4)
  
  # Boundary separation calculation (a)
  a = s2 * qlogis(Pc) / v
  
  # Mean decision time (MDT) calculation
  y = -v * a / s2
  MDT = (a / (2 * v)) * (1 - exp(y)) / (1 + exp(y))
  
  # Non-decision time calculation (Ter)
  Ter = MRT - MDT
  
  return(list(v = v, a = a, Ter = Ter))
}

# Clean and preprocess data
data_clean <- data %>%
  filter(!is.na(binary_question_key_resp.rt) & !is.na(binary_question_key_resp.keys) & !is.na(condition)) %>%
  mutate(correct = ifelse(binary_question_key_resp.keys == 'left', 1, 0))  # Adjust this based on your coding of correct responses

  
# Calculate summary statistics by participant and condition
dat_summary <- data_clean %>%
  group_by(participant, condition) %>%
  summarise(
    Pc = mean(correct),  # Proportion correct
    VRT = var(binary_question_key_resp.rt[correct == 1]),  # Variance of RT for correct responses
    MRT = mean(binary_question_key_resp.rt[correct == 1]),  # Mean RT for correct responses
    .groups = 'drop'
  )

# Apply the EZ function to each participant-condition combination
dat_results <- dat_summary %>%
  rowwise() %>%
  mutate(EZ_output = list(EZ(Pc = Pc, VRT = VRT, MRT = MRT))) %>%
  unnest_wider(EZ_output)  # Unnest the list into separate columns for v, a, and Ter

# View the results
print(dat_results)

# Optionally, save the results to a CSV file
write.csv(dat_results, "EZ_model_results.csv", row.names = FALSE)

# Group-analysis

# Summarize data at the group level (averaging across participants in each condition)
dat_group_summary <- data_clean %>%
  group_by(condition) %>%
  summarise(
    Pc = mean(correct),  # Proportion correct
    VRT = var(binary_question_key_resp.rt[correct == 1]),  # Variance of RT for correct responses
    MRT = mean(binary_question_key_resp.rt[correct == 1]),  # Mean RT for correct responses
    .groups = 'drop'
  )

# Apply the EZ function to each group (condition)
dat_group_results <- dat_group_summary %>%
  rowwise() %>%
  mutate(EZ_output = list(EZ(Pc = Pc, VRT = VRT, MRT = MRT))) %>%
  unnest_wider(EZ_output)  # Unnest the list into separate columns for v, a, and Ter

# View the results for group-level analysis
print(dat_group_results)
